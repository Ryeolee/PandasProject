{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b57d5a-0ca1-4705-a0be-3c3333730c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4주차\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import SGDRegressor, LinearRegression, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor, VotingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import missingno as msn\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "print(1)\n",
    "# 데이터 로드 및 전처리\n",
    "life = pd.read_csv(\"./machine.data.csv\")\n",
    "\n",
    "# 결측값 찾기\n",
    "msn.bar(life)\n",
    "\n",
    "# 결측치 처리\n",
    "life.dropna(inplace=True)\n",
    "\n",
    "# 범주형 데이터 수치화\n",
    "dum = pd.get_dummies(life.VendorName, prefix='c', dtype=float)\n",
    "life = pd.concat([life.drop('VendorName', axis=1), dum], axis =1)\n",
    "\n",
    "dum = pd.get_dummies(life.ModelName, prefix='c', dtype=float)\n",
    "life = pd.concat([life.drop('ModelName', axis=1), dum], axis =1)\n",
    "\n",
    "# PRP 관련된 다른 특성들과의 상관계수 값만을 출력\n",
    "result = life.corr()['PRP']\n",
    "\n",
    "# 상관계수 값을 양의 상관계수로 처리\n",
    "result = np.abs(result)\n",
    "\n",
    "# 상관계수를 내림차순으로 정렬하기\n",
    "result.sort_values(ascending=False)\n",
    "\n",
    "# 피처 선택\n",
    "features = result.index.tolist()\n",
    "features.remove('PRP')\n",
    "\n",
    "# 시각화\n",
    "# sns.pairplot(life[features])\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# x, y 값 지정 및 데이터 분류\n",
    "X = life[features]\n",
    "y = life['PRP']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=40)\n",
    "\n",
    "\n",
    "# 피처추출\n",
    "numeric_features = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "# 데이터의 전처리  - 파이프라인 설정\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "   # ('imputer', SimpleImputer(strategy='median')), # 결측값을 해당 열의 중앙값으로 대체\n",
    "    ('scaler', StandardScaler()) # 특성의 평균을 빼고 표준편차로 나누어 각 특성의 분포를 평균 0, 표준편차 1로 만듬\n",
    "])\n",
    "\n",
    "\n",
    "# 전처리를 수행\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 개별 모델 정의\n",
    "lr = LinearRegression()\n",
    "ridge = Ridge()\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "# 앙상블 모델 정의\n",
    "voting_regressor = VotingRegressor(estimators=[\n",
    "    ('lr', lr),\n",
    "    ('ridge', ridge),\n",
    "    ('rf', rf)\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "# 파이프라인 생성\n",
    "# 데이터 전처리 단계와 앙상블 모델을 연결하여 하나의 파이프라인을 생성합니다. 이 파이프라인은 데이터의 전처리와 모델 학습을 한 번에 수행할 수 있도록 합니다.\n",
    "model_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('voting_regressor', voting_regressor)\n",
    "])\n",
    "\n",
    "# 하이퍼파라미터 튜닝\n",
    "param_grid = {\n",
    "    'voting_regressor__ridge__alpha': [0.1, 1.0, 10.0],\n",
    "    'voting_regressor__rf__n_estimators': [50, 100, 200]\n",
    "}\n",
    "\n",
    "# GridSearchCV 설정 및 모델 학습\n",
    "grid_search = GridSearchCV(model_pipeline, param_grid, cv=5, scoring='r2')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 최적 모델로 예측\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# 최적의 모델 선택 및 평가\n",
    "best_model = grid_search.best_estimator_\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_traning_pred = best_model.predict(X_train)\n",
    "mse = mean_squared_error(y_train, y_traning_pred)\n",
    "mae = mean_absolute_error(y_train, y_traning_pred)\n",
    "r2 = r2_score(y_train, y_traning_pred)\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "mse_test = mean_squared_error(y_test, y_pred)\n",
    "mae_test = mean_absolute_error(y_test, y_pred)\n",
    "r2_test = r2_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\"MSE: {mse}, MAE: {mae}, R^2: {r2}\")\n",
    "\n",
    "print(f\"MSE: {mse_test}, MAE: {mae_test}, R^2: {r2_test}\")\n",
    "\n",
    "# 시각화\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "plt.xlabel(\"y_test\")\n",
    "plt.ylabel(\"y_pred\")\n",
    "plt.title(\"PRP\")\n",
    "plt.savefig('PRP.jpg')\n",
    "\n",
    "cv_score = cross_val_score(best_model, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "print(cv_score)\n",
    "cv_mse = -cv_score.mean()\n",
    "print(f'Cross-Validated MSE: {cv_mse}')\n",
    "\n",
    "train_pred = best_model.predict(X_train)\n",
    "train_mse = mean_squared_error(y_train, train_pred)\n",
    "print(f'Training MSE: {train_mse}')\n",
    "\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "print(f'Testing MSE: {test_mse}')\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel(\"Predicted\")\n",
    "plt.title('Actual vs Predicted')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.histplot(y_test - y_pred, kde=True)\n",
    "plt.xlabel('Residual')\n",
    "plt.ylabel('Residual Histogram')\n",
    "plt.title('Residual Histogram')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbeba255-16c9-446f-b61c-e81941fb2d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4.1주차\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import SGDRegressor, LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import missingno as msn\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "life = pd.read_csv(\"./machine.data.csv\")\n",
    "print(2)\n",
    "\n",
    "# 결측값 찾기\n",
    "msn.bar(life)\n",
    "\n",
    "# 결측치 처리\n",
    "life.dropna(inplace=True)\n",
    "\n",
    "# 범주형 데이터 수치화\n",
    "dum = pd.get_dummies(life.VendorName, prefix='c', dtype=float)\n",
    "life = pd.concat([life.drop('VendorName', axis=1), dum], axis =1)\n",
    "print(life)\n",
    "dum = pd.get_dummies(life.ModelName, prefix='c', dtype=float)\n",
    "life = pd.concat([life.drop('ModelName', axis=1), dum], axis =1)\n",
    "\n",
    "# PRP 관련된 다른 특성들과의 상관계수 값만을 출력\n",
    "result = life.corr()['PRP']\n",
    "\n",
    "# 상관계수 값을 양의 상관계수로 처리\n",
    "result = np.abs(result)\n",
    "\n",
    "# 상관계수를 내림차순으로 정렬하기\n",
    "result.sort_values(ascending=False)\n",
    "\n",
    "# 피처 선택\n",
    "features = result.index.tolist()\n",
    "features.remove('PRP')\n",
    "\n",
    "# 시각화\n",
    "# sns.pairplot(life[features])\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# x, y 값 지정 및 데이터 분류\n",
    "X = life[features]\n",
    "y = life['PRP']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=40)\n",
    "\n",
    "\n",
    "# 피처추출\n",
    "numeric_features = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "# 데이터의 전처리  - 파이프라인 설정\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "   # ('imputer', SimpleImputer(strategy='median')), # 결측값을 해당 열의 중앙값으로 대체\n",
    "    ('scaler', StandardScaler()) # 특성의 평균을 빼고 표준편차로 나누어 각 특성의 분포를 평균 0, 표준편차 1로 만듬\n",
    "])\n",
    "\n",
    "\n",
    "# 전처리를 수행\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# 개별 모델 정의\n",
    "\n",
    "models = [ ('lr', LinearRegression()),\n",
    "          ( 'sgd', SGDRegressor( )) ]\n",
    "\n",
    "# 앙상블 모델 정의\n",
    "ensemble = VotingRegressor(estimators = models)\n",
    "\n",
    "\n",
    "# 모델 파이프라인 생성\n",
    "model_pipeline = Pipeline(steps = [\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('ensemble', ensemble)\n",
    "])\n",
    "\n",
    "# 하이퍼파라미터 튜닝\n",
    "param_grid = {\n",
    "    'ensemble__sgd__alpha': [0.0001, 0.1, 1.0],\n",
    "    'ensemble__sgd__max_iter': [1000, 2000, 3000]\n",
    "}\n",
    "\n",
    "# GridSearchCV 설정 및 모델 학습\n",
    "grid_search = GridSearchCV(model_pipeline, param_grid, cv=5, scoring='neg_mean_squared_error',\n",
    "                           return_train_score=True)\n",
    "grid_search.fit(X_train,y_train)\n",
    "\n",
    "# 최적 파라미터 출력\n",
    "print(f\"Best parameters found :{grid_search.best_params_}\")\n",
    "\n",
    "# 최적 모델로 예측\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "y_traning_pred = best_model.predict(X_train)\n",
    "mse = mean_squared_error(y_train, y_traning_pred)\n",
    "mae = mean_absolute_error(y_train, y_traning_pred)\n",
    "r2 = r2_score(y_train, y_traning_pred)\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "mse_test = mean_squared_error(y_test, y_pred)\n",
    "mae_test = mean_absolute_error(y_test, y_pred)\n",
    "r2_test = r2_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\"MSE: {mse}, MAE: {mae}, R^2: {r2}\")\n",
    "\n",
    "print(f\"MSE: {mse_test}, MAE: {mae_test}, R^2: {r2_test}\")\n",
    "\n",
    "# 시각화\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "plt.xlabel(\"y_test\")\n",
    "plt.ylabel(\"y_pred\")\n",
    "plt.title(\"PRP\")\n",
    "plt.savefig('PRP.jpg')\n",
    "\n",
    "cv_score = cross_val_score(best_model, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "print(cv_score)\n",
    "cv_mse = -cv_score.mean()\n",
    "print(f'Cross-Validated MSE: {cv_mse}')\n",
    "\n",
    "train_pred = best_model.predict(X_train)\n",
    "train_mse = mean_squared_error(y_train, train_pred)\n",
    "print(f'Training MSE: {train_mse}')\n",
    "\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "print(f'Testing MSE: {test_mse}')\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel(\"Predicted\")\n",
    "plt.title('Actual vs Predicted')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.histplot(y_test - y_pred, kde=True)\n",
    "plt.xlabel('Residual')\n",
    "plt.ylabel('Residual Histogram')\n",
    "plt.title('Residual Histogram')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e70295-ed2f-4ac2-8f85-153cc001d59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Load data\n",
    "life = pd.read_csv(\"./machine.data.csv\")\n",
    "life.dropna(inplace=True)\n",
    "life = pd.get_dummies(life, columns=['VendorName', 'ModelName'], drop_first=True)\n",
    "\n",
    "# Feature selection based on correlation\n",
    "result = np.abs(life.corr()['PRP'])\n",
    "features = result[result > 0.3].index.tolist()\n",
    "features.remove('PRP')\n",
    "\n",
    "# Data split\n",
    "X = life[features]\n",
    "y = life['PRP']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Linear Regression Model\n",
    "# 전처리\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 모델 학습\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 모델 평가\n",
    "y_train_pred = model.predict(X_train_scaled)\n",
    "lr_train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "lr_train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "lr_train_r2 = r2_score(y_train, y_train_pred)\n",
    "\n",
    "# 테스트 데이터 평가\n",
    "test_pred = model.predict(X_test)\n",
    "lr_test_mse = mean_squared_error(y_test, test_pred)\n",
    "lr_test_mae = mean_absolute_error(y_test, test_pred)\n",
    "lr_test_r2 = r2_score(y_test, test_pred)\n",
    "\n",
    "\n",
    "# 교차 검증\n",
    "cv_score = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='r2')\n",
    "print(f\"Cross-Validated R^2: {cv_score.mean()}\")\n",
    "\n",
    "print(f\"Training MSE: {lr_train_mse}\")\n",
    "print(f\"Training MAE: {lr_train_mae}\")\n",
    "print(f\"Training R^2: {lr_train_r2}\")\n",
    "\n",
    "print(f\"Testing MSE: {lr_test_mse}\")\n",
    "print(f\"Testing MAE: {lr_test_mae}\")\n",
    "print(f\"Testing R^2: {lr_test_r2}\")\n",
    "\n",
    "\n",
    "# # GridSearchCV for Best Estimator\n",
    "# param_grid = {\n",
    "#     'model__fit_intercept': [True, False]\n",
    "# }\n",
    "# grid_search = GridSearchCV(lr_model, param_grid, cv=5, scoring='r2')\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# # Best estimator evaluation\n",
    "# best_model = grid_search.best_estimator_\n",
    "# best_model.fit(X_train, y_train)\n",
    "# y_train_pred_best = best_model.predict(X_train)\n",
    "# best_train_mse = mean_squared_error(y_train, y_train_pred_best)\n",
    "# best_train_mae = mean_absolute_error(y_train, y_train_pred_best)\n",
    "# best_train_r2 = r2_score(y_train, y_train_pred_best)\n",
    "\n",
    "# y_test_pred_best = best_model.predict(X_test)\n",
    "# best_test_mse = mean_squared_error(y_test, y_test_pred_best)\n",
    "# best_test_mae = mean_absolute_error(y_test, y_test_pred_best)\n",
    "# best_test_r2 = r2_score(y_test, y_test_pred_best)\n",
    "\n",
    "# best_cv_scores = cross_val_score(best_model, X, y, cv=5, scoring='r2')\n",
    "# best_cv_mean_r2 = best_cv_scores.mean()\n",
    "\n",
    "# # Create DataFrame with results\n",
    "# results = pd.DataFrame({\n",
    "#     'Model': ['Linear Regression', 'Linear Regression', 'Best_estimator', 'Best_estimator', 'Linear Regression Cross Validation', 'Best_estimator Cross Validation'],\n",
    "#     'Data': ['Train', 'Test', 'Train', 'Test', 'Cross Validation', 'Cross Validation'],\n",
    "#     'MSE': [lr_train_mse, lr_test_mse, best_train_mse, best_test_mse, -cross_val_score(lr_model, X, y, cv=5, scoring='neg_mean_squared_error').mean(), -cross_val_score(best_model, X, y, cv=5, scoring='neg_mean_squared_error').mean()],\n",
    "#     'MAE': [lr_train_mae, lr_test_mae, best_train_mae, best_test_mae, -cross_val_score(lr_model, X, y, cv=5, scoring='neg_mean_absolute_error').mean(), -cross_val_score(best_model, X, y, cv=5, scoring='neg_mean_absolute_error').mean()],\n",
    "#     'R^2': [lr_train_r2, lr_test_r2, best_train_r2, best_test_r2, lr_cv_mean_r2, best_cv_mean_r2]\n",
    "# })\n",
    "\n",
    "# print(results)\n",
    "\n",
    "# # Plotting the results\n",
    "# fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(18, 6))\n",
    "\n",
    "# # MSE Comparison\n",
    "# results.pivot(index='Model', columns='Data', values='MSE').plot(kind='bar', ax=axes[0], title='MSE Comparison')\n",
    "\n",
    "# # MAE Comparison\n",
    "# results.pivot(index='Model', columns='Data', values='MAE').plot(kind='bar', ax=axes[1], title='MAE Comparison')\n",
    "\n",
    "# # R^2 Comparison\n",
    "# results.pivot(index='Model', columns='Data', values='R^2').plot(kind='bar', ax=axes[2], title='R^2 Comparison')\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d609a5ba-93f1-4def-99db-9334aa48a456",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3f5e62-196e-4190-8695-42174119f6c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
